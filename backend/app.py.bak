import json
import os
import sys
import asyncio
from typing import List, Optional, AsyncGenerator
from pathlib import Path
from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, JSONResponse, StreamingResponse

# 即使不再使用 example.chat，保留引用以防有其他依赖
import example 

from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, AIMessageChunk
import operator as op
from typing import Any, Dict

from langchain.tools import tool
from langchain_openai import ChatOpenAI

from langgraph.graph import StateGraph, START, END, MessagesState
from langgraph.prebuilt import ToolNode, tools_condition
from langgraph.checkpoint.memory import MemorySaver
# 假设你的构建逻辑在这个文件里
from agent.build_graph import graph_builder

# -----------------------------
# 编译 + 记忆（Checkpointer）
# -----------------------------
# MemorySaver：把每一步 state checkpoint 存起来，用 thread_id 实现“多轮记忆”
checkpointer = MemorySaver()
agent_app = graph_builder.compile(checkpointer=checkpointer)

# Load environment variables from env.sh if present
env_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "env.sh")
if os.path.exists(env_path):
    print(f"Loading environment from {env_path}")
    with open(env_path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if line.startswith("export "):
                content = line[7:].strip()
                if "=" in content:
                    key, value = content.split("=", 1)
                    key = key.strip()
                    value = value.strip()
                    if (value.startswith('"') and value.endswith('"')) or \
                       (value.startswith("'" ) and value.endswith("'" )):
                        value = value[1:-1]
                    if " # " in value:
                        value = value.split(" # ")[0].strip()
                    os.environ[key] = value

# Setup path for agent import - Removed as part of refactoring
# current_dir = os.path.dirname(os.path.abspath(__file__))
# agent_path = os.path.join(current_dir, "xintuoyin-KLCLAB")
# if agent_path not in sys.path:
#    sys.path.append(agent_path)

app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

HISTORY_DIR = Path("history_storage")
HISTORY_DIR.mkdir(exist_ok=True)

def get_history_file(conv_id: str) -> Path:
    safe_id = "".join(c for c in conv_id if c.isalnum() or c in ('-', '_'))
    return HISTORY_DIR / f"{safe_id}.json"

def load_history(conv_id: str) -> List[dict]:
    file_path = get_history_file(conv_id)
    if file_path.exists():
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            print(f"Error loading history for {conv_id}: {e}")
    return []

def save_history(conv_id: str, messages: List[dict]):
    file_path = get_history_file(conv_id)
    try:
        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(messages, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"Error saving history for {conv_id}: {e}")

async def read_upload_files(files: List[UploadFile]):
    used = []
    parts = []
    for f in files or []:
        used.append(f.filename)
        try:
            content = await f.read()
            if not isinstance(content, (bytes, bytearray)):
                content = str(content).encode("utf-8", errors="ignore")
            mime = f.content_type or "application/octet-stream"
            if mime.startswith("text/") or mime in ["application/json", "application/xml"]:
                text = content.decode("utf-8", errors="ignore")
                if len(text) > 4000:
                    text = text[:4000] + "\n...[truncated]"
                parts.append(f"文件 {f.filename} 内容:\n{text}")
            else:
                parts.append(f"文件 {f.filename}（{mime}，{len(content)} bytes）已上传，内容未展开")
        except Exception:
            parts.append(f"读取文件 {f.filename} 失败")
    return used, "\n\n".join(parts) if parts else ""

# API Routes
@app.post("/api/chat")
async def chat_api(
    message: str = Form(...),
    files: List[UploadFile] = File(None),
    system_prompt: Optional[str] = Form("You are a helpful assistant"),
    conversation_id: Optional[str] = Form(None),
    history: Optional[str] = Form(None), 
    stream: bool = Form(False),
    web_search: bool = Form(False),
    db_version: Optional[str] = Form(None)
):
    used_files, files_text = await read_upload_files(files)
    
    # 1. 构建当前用户消息内容
    user_content = message
    if db_version:
        # 放在后面作为强指令，比放在前面更不容易被遗忘
        user_content = f"从数据库{db_version}中{user_content}" 

    if files_text:
        user_content += "\n\n--- Uploaded Files Content ---" + files_text
    
    print(f"Received chat request: id={conversation_id}, web_search={web_search}, db_version={db_version}")
    print(f"Final User Message to AI: {user_content[:100]}...")
    
    current_user_msg_dict = {"role": "user", "content": user_content}

    # 2. 准备 LangGraph 需要的 inputs
    lang_messages = [HumanMessage(content=user_content)]

    if system_prompt:
        lang_messages.insert(0, SystemMessage(content=system_prompt))

    inputs = {
        "messages": lang_messages, 
        "enable_web": web_search 
    }

    config = {"configurable": {"thread_id": conversation_id or "default_thread"}}

    # 3. 定义异步生成器 (Real Streaming)
    async def iter_stream() -> AsyncGenerator[str, None]:
        full_response_text = ""
        
        try:
            async for msg, metadata in agent_app.astream(inputs, config, stream_mode="messages"):
                
                node_name = metadata.get("langgraph_node", "unknown")
                
                # 修改：只保留最终回答节点，隐藏中间的 SQL 生成过程 (sql_planner)
                valid_nodes = ["chatbot_web", "chatbot_local"]
                
                if isinstance(msg, AIMessageChunk) and msg.content:
                    if node_name in valid_nodes:
                        yield msg.content
                        full_response_text += msg.content
            
            # --- 流结束后保存历史 ---
            if conversation_id and full_response_text:
                server_history = load_history(conversation_id)
                clean_history = [m for m in server_history if m.get("role") != "system"]
                clean_history.append(current_user_msg_dict)
                clean_history.append({"role": "assistant", "content": full_response_text})
                save_history(conversation_id, clean_history)
                print(f"History saved for {conversation_id}")

        except Exception as e:
            print(f"Streaming Error: {e}")
            yield f"\n[System Error: {str(e)}]"

    # 4. 执行
    if agent_app:
        if stream:
            return StreamingResponse(iter_stream(), media_type="text/plain")
        else:
            try:
                result = await agent_app.ainvoke(inputs, config)
                final_msg = result["messages"][-1]
                content = final_msg.content
                
                if conversation_id:
                    server_history = load_history(conversation_id)
                    clean_history = [m for m in server_history if m.get("role") != "system"]
                    clean_history.append(current_user_msg_dict)
                    clean_history.append({"role": "assistant", "content": content})
                    save_history(conversation_id, clean_history)

                return {
                    "role": "assistant",
                    "content": content,
                    "files_processed": used_files
                }
            except Exception as e:
                 return JSONResponse(status_code=500, content={"error": str(e)})
    else:
        return JSONResponse(status_code=500, content={"error": "Agent app is not initialized."})

@app.delete("/api/chat/{conversation_id}")
async def delete_chat_history(conversation_id: str):
    file_path = get_history_file(conversation_id)
    if file_path.exists():
        try:
            os.remove(file_path)
            print(f"Deleted history file: {file_path}")
            return {"status": "success", "message": f"History for {conversation_id} deleted."}
        except Exception as e:
            print(f"Error deleting history file {file_path}: {e}")
            return JSONResponse(status_code=500, content={"error": f"Failed to delete history: {str(e)}"})
    return {"status": "ignored", "message": "File not found."}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("app:app", host="0.0.0.0", port=int(os.environ.get("PORT", "8000")), reload=False)
