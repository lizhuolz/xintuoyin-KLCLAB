# agent_cli.py / core_agt.py
import operator as op
import openai # å¼•å…¥ openai ä»¥æ•è· Azure é”™è¯¯
from typing import Any, Dict

# LangChain/LangGraph ç»„ä»¶
from langchain_core.messages import AIMessageChunk
from langgraph.checkpoint.memory import MemorySaver
# æ›¿æ¢æˆä½ å®é™…çš„ import è·¯å¾„
from agent.build_graph import graph_builder 

# ==========================================
# ğŸ”¥ å®‰å…¨é˜²ç«å¢™é…ç½®
# ==========================================
from llm_guard.vault import Vault
from llm_guard import scan_prompt, scan_output
# æ³¨æ„ï¼šè¿™é‡Œä¸å†ä» input_scanners å¼•å…¥ BanTopics
from llm_guard.input_scanners import (
    Anonymize, BanSubstrings, Gibberish, InvisibleText, 
    PromptInjection, Secrets, TokenLimit, Toxicity
)
from llm_guard.output_scanners import NoRefusal, Deanonymize, BanTopics

# 1. åˆå§‹åŒ–
print("æ­£åœ¨åˆå§‹åŒ–å®‰å…¨é˜²ç«å¢™...")
vault = Vault()

# 2. å®šä¹‰è¾“å…¥é˜²å¾¡å±‚ (Input Scanners)
# âŒ å·²ç§»é™¤ BanTopics (å®ƒä¼šå¯¼è‡´æŠ¥é”™)
# âœ… ä¿ç•™ BanSubstrings (å®ƒè´Ÿè´£æ‹¦æˆªç‚¸å¼¹ã€åˆ¶æ¯’ç­‰å…³é”®è¯)
input_scanners = [
    # æ ¸å¿ƒæ‹¦æˆªï¼šåªè¦å‡ºç°è¿™äº›è¯ï¼Œç›´æ¥æ‹’ç»
    BanSubstrings(
        substrings=[
            "ç‚¸å¼¹", "çˆ†ç‚¸ç‰©", "ç”ŸåŒ–æ­¦å™¨", "åˆ¶æ¯’", "æ€äºº", 
            "è‡ªæ€", "æ ¸æ­¦å™¨", "æªæ”¯", "ç«è¯", "ç¡é…¸é“µ",
            "ignore previous instructions", "system prompt"
        ],
        match_type="str",
        case_sensitive=False
    ),
    PromptInjection(threshold=0.5),
    InvisibleText(),
    Secrets(redact_mode="partial"),
    Anonymize(vault=vault),
    TokenLimit(limit=2000),
    Toxicity(threshold=0.5),
    Gibberish(threshold=0.5),
]

# 3. å®šä¹‰è¾“å‡ºé˜²å¾¡å±‚ (Output Scanners)
# è¿™é‡Œå¯ä»¥æ”¾ BanTopicsï¼Œç”¨æ¥æ£€æŸ¥ç”Ÿæˆçš„ç»“æœæ˜¯å¦åŒ…å«å±é™©è¯é¢˜
output_scanners = [
    NoRefusal(),
    # å¦‚æœä¹‹å‰ BanTopics åœ¨è¾“å‡ºç«¯ä¹ŸæŠ¥é”™ï¼Œå¯ä»¥å…ˆæ³¨é‡Šæ‰ä¸‹é¢è¿™è¡Œï¼Œç¡®ä¿ç¨‹åºè·‘é€š
    BanTopics(topics=["explosives", "weapons"], threshold=0.6), 
    Deanonymize(vault=vault)
]
print("âœ… é˜²ç«å¢™åŠ è½½å®Œæ¯•")

# ç¼–è¯‘ Graph
checkpointer = MemorySaver()
app = graph_builder.compile(checkpointer=checkpointer)

def main():
    print("LangGraph Agent (Secure Mode) å·²å¯åŠ¨ã€‚è¾“å…¥ exit é€€å‡ºã€‚")
    thread_id = "demo-thread-secure"

    while True:
        try:
            user_text = input("\nYou: ").strip()
        except EOFError:
            break

        if not user_text:
            continue
        if user_text.lower() in ("exit", "quit"):
            break

        # ==========================================
        # ğŸ”¥ 1. æœ¬åœ°é˜²ç«å¢™æ£€æŸ¥ (Input)
        # ==========================================
        try:
            # è¿™é‡Œè°ƒç”¨ input_scannersï¼Œé‡Œé¢å·²ç»æ²¡æœ‰ BanTopics äº†ï¼Œä¸ä¼šå†æŠ¥é”™
            sanitized_prompt, results_valid, results_score = scan_prompt(input_scanners, user_text)
            
            if any(not is_valid for is_valid in results_valid.values()):
                print("\nğŸ›‘ [æœ¬åœ°æ‹¦æˆª] è¾“å…¥è¢«é˜²ç«å¢™æ‹’ç»ï¼š") # [OUTPUT]
                for scanner_name, is_valid in results_valid.items():
                    if not is_valid:
                        score = results_score.get(scanner_name, 0)
                        # å¦‚æœæ˜¯ BanSubstrings æ‹¦æˆªçš„ï¼Œè¯´æ˜å‘½ä¸­äº†ç‚¸å¼¹ç­‰å…³é”®è¯
                        print(f"   âŒ {scanner_name} (åˆ†å€¼: {score})")
                continue
        except Exception as e:
            print(f"æœ¬åœ°é˜²ç«å¢™å‡ºé”™: {e}")


        # ==========================================
        # 2. æ‰§è¡Œ Agent
        # ==========================================
        config = {"configurable": {"thread_id": thread_id}}
        inputs = {
            "messages": [("user", sanitized_prompt)],
            "enable_web": True,
            "select_model": "gpt-4o"
        }

        print("Agent: ", end="", flush=True)
        full_response_text = ""

        try:
            for msg, metadata in app.stream(inputs, config, stream_mode="messages"):
                node_name = metadata.get("langgraph_node", "unknown")
                if isinstance(msg, AIMessageChunk) and msg.content and node_name in ["chatbot_web","chatbot_local"]:
                    print(msg.content, end="", flush=True)
                    full_response_text += msg.content
        
        except openai.BadRequestError as e:
            if e.code == 'content_filter':
                print("\n\nğŸ›¡ï¸ [Azure äº‘ç«¯æ‹¦æˆª] å†…å®¹è¿åäº† Azure å®‰å…¨ç­–ç•¥ (æš´åŠ›/ä»‡æ¨/è¶Šç‹±)ã€‚")
            else:
                print(f"\n\nâŒ OpenAI è¯·æ±‚é”™è¯¯: {e}")
        except Exception as e:
            print(f"\n\nâŒ ç³»ç»Ÿè¿è¡Œé”™è¯¯: {e}")

        print("") 

        # ==========================================
        # 3. è¾“å‡ºå®¡è®¡ (Output)
        # ==========================================
        if full_response_text:
            try:
                # BanTopics åœ¨è¿™é‡Œï¼ˆoutput_scannersï¼‰æ‰æ˜¯åˆæ³•çš„
                _, out_valid, _ = scan_output(output_scanners, sanitized_prompt, full_response_text)
                if any(not is_valid for is_valid in out_valid.values()):
                     print("\nâš ï¸ [å†…å®¹è­¦å‘Š] å›å¤å†…å®¹å¯èƒ½è¿åå®‰å…¨ç­–ç•¥") # [OUTPUT]  full_response_text += "\n[å†…å®¹è­¦å‘Š] å›å¤å†…å®¹å¯èƒ½è¿åå®‰å…¨ç­–ç•¥"
                     for k, v in out_valid.items():
                         if not v: print(f"   - {k} è¿è§„")
            except Exception as e:
                # å³ä½¿è¾“å‡ºæ£€æŸ¥å‡ºé”™ï¼Œä¹Ÿä¸è¦è®©ç¨‹åºå´©æºƒï¼Œæ‰“å°æ—¥å¿—å³å¯
                print(f"[å®¡è®¡è·³è¿‡] è¾“å‡ºæ£€æŸ¥å‡ºé”™: {e}")

if __name__ == "__main__":
    main()